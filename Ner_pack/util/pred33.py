# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13pv0IPyIHZ1VyRGfnvZa5wwUlTWpCTFH
"""

# -*- coding: utf-8 -*-
"""pred2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xc5Kf9SHYqA11i0lxpR5Uvp4xbkG4Jx5

# **IMPORT**
"""


# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from keras.preprocessing.sequence import pad_sequences
from keras.models import load_model
from keras_contrib.layers import CRF
import pickle
from keras_contrib.losses import  crf_loss
from keras_contrib.metrics import crf_viterbi_accuracy

from keras.utils import to_categorical
from keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional
from keras.models import Model, Input
from keras.callbacks import ModelCheckpoint
from nltk.tokenize import TweetTokenizer
import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

from sklearn_crfsuite.metrics import flat_classification_report
from sklearn.metrics import f1_score
from seqeval.metrics import precision_score, recall_score, f1_score, classification_report
from keras.preprocessing.text import text_to_word_sequence
import pickle
import pandas as pd
import numpy as np
from keras.preprocessing.sequence import pad_sequences
from keras.models import load_model
from keras_contrib.layers import CRF
import pickle
from keras_contrib.losses import  crf_loss
from keras_contrib.metrics import crf_viterbi_accuracy

from keras.utils import to_categorical
from keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional
from keras.models import Model, Input
from keras.callbacks import ModelCheckpoint
from nltk.tokenize import TweetTokenizer
import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

from sklearn_crfsuite.metrics import flat_classification_report
from sklearn.metrics import f1_score
from seqeval.metrics import precision_score, recall_score, f1_score, classification_report
from keras.preprocessing.text import text_to_word_sequence
import pickle



"""# **LOAD DATA**"""
df = pd.read_csv('/content/NER1/Ner_pack/Dataset/updated_use_NER', encoding = "ISO-8859-1")
word_to_index=pickle.load(open('/content/NER1/Ner_pack/ner_files/word_to_index1.pickle','rb'))
tag_to_index=pickle.load(open('/content/NER1/Ner_pack/ner_files/tag_to_index1.pickle','rb'))
model= load_model('/content/NER1/Ner_pack/model/model11.h5',custom_objects={'CRF':CRF, 
                                                  'crf_loss':crf_loss, 
                                                  'crf_viterbi_accuracy':crf_viterbi_accuracy})


idx2word = {i: w for w, i in word_to_index.items()}
idx2tag = {i: w for w, i in tag_to_index.items()}
words = list(df['Word'].unique())
tags = list(df['Tag'].unique())

sw=['-',"'",'i','me','them','they','himself','herslf','yourself','myself','their','here','of','on','+']
date='january february march april may june july august september october november december'
money='rs rupees $ dollars euro pound rupiah bucks'
day='1st 2nd 3rd 4th 5th 6th 7th 8th 9th 10th 11th 12th 13th 14th 15th 16th 17th 18th 19th 20th 21st 22nd 23rd 24th 25th 26th 27th 28th 29th 30th 31st  sunday monday tuesday wednesday thursday friday saturday '

comp_dict={'facebook':'social',
'linkdiln':'social',
'instagram':'social',
'ola':'cab',
'uber':'cab',
'zomato':'f-deliver',
'swiggy':'f-deliver',
'airtel':'phone',
'Reliance jio':'phone',
'vodaphone':'phone',
'idea':'phone',
'email':'social',
'ola bike':'cab',
'oyo':'hotel',
'bookmytrip':'travel',
'whatsapp':'social',
'google':'search',
'pubg':'game',
'HDFC Bank':'bank',
'Axis Bank':'bank',
'IDFC First Bank':'bank',
'State Bank of India':'bank',
'SBI':'bank',
'Bank Of Baroda':'bank',
'Punjab National Bank':'bank',
'ICICI Bank':'bank',
'Canara Bank':'bank',
'United bank of india':'bank',
'UBI':'bank',
'union bank of india':'bank'}

comp="Ogenie facebook linkdiln instagram ola uber zomato swiggy airtel Reliance jio vodaphone idea email ola bike oyo whatsapp google pubg HDFC Bank. Axis Bank. IDFC First Bank. State Bank of India. SBI Bank Of Baroda. Punjab National Bank. ICICI Bank. Canara Bank United bank of india UBI union bank of india.lower"

loc={'a':'arunachal pradesh andra pradesh Afghanistan Akrotiri Albania Algeria American Samoa Andorra Angola Anguilla Antarctica Antigua and BarbudaArgentina Armenia Aruba Ashmore and Cartier Islands Australia Austria Azerbaijan'.lower(),
'b':"bangalore Bahamas The Bahrain Bangladesh Barbados Bassas da India Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bosnia and Herzegovina Botswana Bouvet Island Brazil British Indian Ocean Territory British Virgin Islands Brunei Bulgaria Burkina Faso Burma Burundi".lower(),
'c':"Cambodia Cameroon Canada Cape Verde Cayman Islands Central African Republic Chad Chile China Christmas Island Clipperton Island Cocos (Keeling) Islands Colombia Comoros Congo, Democratic Republic of the Congo, Republic of the Cook Islands Coral Sea Islands Costa Rica Cote d'Ivoire Croatia Cuba Cyprus Czech Republic".lower(),
'd':'delhi Denmark Dhekelia Djibouti Dominica Dominican Republic'.lower(),
'e':'Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Ethiopia Europa Island'.lower(),
'f':'Falkland Islands (Islas Malvinas) Faroe Islands Fiji Finland France French Guiana French Polynesia French Southern and Antarctic Lands'.lower(),
'g':'goa Gujrath Gabon Gambia, The Gaza Strip Georgia Germany Ghana Gibraltar Glorioso Islands Greece Greenland Grenada Guadeloupe Guam Guatemala Guernsey Guinea Guinea-Bissau Guyana'.lower(),
'h':'himachal pradesh hyderabad Haiti Heard Island and McDonald Islands Holy See (Vatican City) Honduras Hong Kong Hungary'.lower(),
'i':'indore Iceland India Indonesia Iran Iraq Ireland Isle of Man Israel Italy'.lower(),
'j':'Jamaica Jan Mayen Japan Jersey Jordan Juan de Nova Island'.lower(),
'k':'karnataka kerela Kazakhstan Kenya Kiribati Korea, North Korea, South Kuwait Kyrgyzstan kolkata'.lower() ,
'l':'Laos Latvia Lebanon Lesotho Liberia Libya Liechtenstein Lithuania Luxembourg'.lower(),
'm':'maharashtramumbai Macau Macedonia Madagascar Malawi Malaysia Maldives Mali Malta Marshall Islands Martinique Mauritania Mauritius Mayotte Mexico Micronesia, Federated States of Moldova Monaco MongoliaMontserrat Morocco Mozambique'.lower(),
'n':'noida Namibia Nauru Navassa Island Nepal Netherlands Netherlands Antilles New Caledonia New Zealand Nicaragua Niger Nigeria Niue Norfolk Island Northern Mariana Islands Norway'.lower(),
'o':'Oman orrisa'.lower(),
'p':'Pakistan Palau Panama Papua New Guinea Paracel Islands Paraguay Peru Philippines Pitcairn Islands Poland Portugal Puerto Rico'.lower(),
'q':'Qatar'.lower(),
'r':'Reunion Romania Russia Rwanda'.lower(),
's':'shimla Saint Helena Saint Kitts and Nevis Saint Lucia Saint Pierre and Miquelon Saint Vincent and the Grenadines Samoa San Marino Sao Tome and Principe Saudi Arabia Senegal Serbia and Montenegro Seychelles Sierra Leone Singapore Slovakia Slovenia Solomon Islands Somalia South Africa South Georgia and the South Sandwich Islands Spain Spratly Islands Sri Lanka Sudan Suriname Svalbard Swazil and Sweden Switzerland Syria'.lower(),
't':'Taiwan Tajikistan Tanzania Thailand Timor-Leste Togo Tokelau Tonga Trinidad and Tobago Tromelin Island Tunisia Turkey Turkmenistan Turks and Caicos Islands Tuvalu'.lower(),
'u':'Uganda Ukraine United Arab Emirates United Kingdom United States Uruguay Uzbekistan'.lower(),
'v':'vellore Vanuatu Venezuela Vietnam Virgin Islands'.lower(),
'w':'Wake Island Wallis and Futuna West Bank Western Sahara west bengal'.lower(),
'y':'Yemen'.lower(),
'z':'Zambia Zimbabwe'.lower()}

"""# **PREDICTION**"""

# Commented out IPython magic to ensure Python compatibility.
# %time AI_entity('i want to fly from mumbai to kolkata on 2nd may with rs 3 2pm')

def power(x,y):
    return x**y

#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

def AI_RB_entity(s):
  dict1={}

  if type(s)==str:
    print('The entities are...')
  else:
    print('Sorrry !!!! Datatype did not match')
    print('Please give a string input')
    print(' '*80)
    print('    For example')
    print('*'*80)
    print('"I want to book the show at 12 am on 25th july"')
    print('*'*80)
    return
  dict={}
  import re
  email=re.findall("([a-zA-Z0-9+._-]+@[a-zA-Z._-]+\.[a-zA-Z_-]+)", s)
  phone=re.findall("(?:\s+|)((0|(?:(\+|)91))(?:\s|-)*(?:(?:\d(?:\s|-)*\d{9})|(?:\d{2}(?:\s|-)*\d{8})|(?:\d{3}(?:\s|-)*\d{7}))|\d{10})(?:\s+|)", s)
  phone=set(phone)
  phone_no=[]
  for i in phone:
     phone_no.append(max(i))
  if len(phone_no)>0:
     dict['phone']=phone_no
  if len(email)>0:
     dict['email']=email
  

  ss=s.lower()
  tknzr = TweetTokenizer()
  s3=tknzr.tokenize(ss)
  
  # nlp = en_core_web_sm.load()
  # doc=nlp(s)
  # list1=[]
  # for X in doc:
  #   list1.append((str(X).lower()))
  # s3=list1

  s1=[]
  s2=[]
  for i in s3:
    if i not in sw:
       s2.append(i)
  for i in s2:
      if word_to_index.get(i)==None:
          i='unk'
      s1.append(i)
  list4=[]
  company={}

  import re
  mem1=0
  mem2=0
  for i in range(0,len(s1)):
    if s1[i]=='from':
        mem1=mem1+1
    elif s1[i]=='to':
        mem2=mem2+1
    elif s1[i]=='unk':
       if 65<=ord(s2[i][0])>=90 or 97<=ord(s2[i][0])>=122:
          if len(re.findall(s2[i],loc[s2[i][0]]))>0:
              list4.append(s2[i])
       else:
          pass

       if  len(re.findall(s2[i],comp))>0:
          for g in comp_dict:
            if g==s2[i]:
               company[s2[i]]=(comp_dict[s2[i]])
       else:
          pass
        
       
       if mem1>0:
            if len(re.findall(s2[i],loc[s2[i][0]]))>0:
                mem1=mem1-1
                dict['start']=s2[i]
            else:
                dict['person']=s2[i]
    
       elif mem2>0:
            if len(re.findall(s2[i],loc[s2[i][0]]))>0:
                mem2=mem2-1

                dict['destination']=s2[i]
                mem2=0
        
  
    elif len(re.findall(s2[i],day))>0:
        if i+1<len(s2):
          if  len(re.findall(s2[i+1],date))>0:
              dict['date']=' '.join([s2[i],s2[i+1]])
          elif s2[i+1] =='am' or s2[i+1]=='pm':
              dict['time']=' '.join([s2[i],s2[i+1]])

    if s2[i].isdigit():
        if len(re.findall(s2[i-1],money))>0:
           dict['money']=' '.join([s2[i],s2[i-1]])

        elif  i+1<len(s2):
           if len(re.findall(s2[i+1],money))>0:
              dict['money']=' '.join([s2[i],s2[i+1]])

  if len(list4)>0:
     dict['location']=list4
  if len(company)>0:

     dict['comapany']=company
  X = [word_to_index.get(i,1) for i in s.split()]
  X = pad_sequences(maxlen = 75, sequences = [X], padding = "post", value = word_to_index["PAD"])
  p = model.predict(np.array(X))
  p = np.argmax(p, axis=-1)
  for w, pred in zip(X[0], p[0]):
     if w != 0 and words[w-2]!='Bermel' and idx2tag[pred]!='PAD' and  idx2tag[pred]!='O' and words[w-2]!='UNK':
        # print("{:15}: {}".format(words[w-2], idx2tag[pred]))
        dict[words[w-2]]=idx2tag[pred]

  
  

  return(dict)

#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
from nltk.tokenize import TweetTokenizer
dict={}
def RB_entity(s):
  
  if type(s)==str:
    print("The entities are ...")
    # print('This are the useful entity')
  else:
    print('Sorrry !!!! Datatype did not match')
    print('Please give a string input')
    print(' '*80)
    print('    For example')
    print('*'*80)
    print('"I want to book the show at 12 am on 25th july"')
    print('*'*80)
    return
  dict={}
  import re
  email=re.findall("([a-zA-Z0-9+._-]+@[a-zA-Z._-]+\.[a-zA-Z_-]+)", s)
  phone=re.findall("(?:\s+|)((0|(?:(\+|)91))(?:\s|-)*(?:(?:\d(?:\s|-)*\d{9})|(?:\d{2}(?:\s|-)*\d{8})|(?:\d{3}(?:\s|-)*\d{7}))|\d{10})(?:\s+|)", s)
  phone=set(phone)
  phone_no=[]
  for i in phone:
     phone_no.append(max(i))
  if len(phone_no)>0:
     dict['phone']=phone_no
  if len(email)>0:
     dict['email']=email
 

  s=s.lower()
  tknzr = TweetTokenizer()
  s3=tknzr.tokenize(s)
  
  # nlp = en_core_web_sm.load()
  # doc=nlp(s)
  # list1=[]
  # for X in doc:
  #   list1.append((str(X).lower()))
  # s3=list1

  s1=[]
  s2=[]
  for i in s3:
    if i not in sw:
       s2.append(i)
  for i in s2:
      if word_to_index.get(i)==None:
          i='unk'
      s1.append(i)
  list4=[]
  company={}

  import re
  mem1=0
  mem2=0
  for i in range(0,len(s1)):
    if s1[i]=='from':
        mem1=mem1+1
    elif s1[i]=='to':
        mem2=mem2+1
    elif s1[i]=='unk':
       if 65<=ord(s2[i][0])>=90 or 97<=ord(s2[i][0])>=122:
          if len(re.findall(s2[i],loc[s2[i][0]]))>0:
              list4.append(s2[i])
       else:
          pass

       if  len(re.findall(s2[i],comp))>0:
          for g in comp_dict:
            if g==s2[i]:
               company[s2[i]]=(comp_dict[s2[i]])
       else:
          pass
        
       
       if mem1>0:
            if len(re.findall(s2[i],loc[s2[i][0]]))>0:
                mem1=mem1-1
                dict['start']=s2[i]
            else:
                dict['person']=s2[i]
    
       elif mem2>0:
            if len(re.findall(s2[i],loc[s2[i][0]]))>0:
                mem2=mem2-1

                dict['destination']=s2[i]
                mem2=0
        
  
    elif len(re.findall(s2[i],day))>0:
        if i+1<len(s2):
          if  len(re.findall(s2[i+1],date))>0:
              dict['date']=' '.join([s2[i],s2[i+1]])
          elif s2[i+1] =='am' or s2[i+1]=='pm':
              dict['time']=' '.join([s2[i],s2[i+1]])

    if s2[i].isdigit():
        if len(re.findall(s2[i-1],money))>0:
           dict['money']=' '.join([s2[i],s2[i-1]])

        elif  i+1<len(s2):
           if len(re.findall(s2[i+1],money))>0:
              dict['money']=' '.join([s2[i],s2[i+1]])

  if len(list4)>0:
     dict['location']=list4
  if len(company)>0:

     dict['comapany']=company
  return(dict)

#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

from nltk.tokenize import TweetTokenizer
dict={}

def AI_entity(s):
  dict={}
  if type(s)==str:
     print('The entities are ...')
  else:
    print('Sorrry !!!! Datatype did not match')
    print('Please give a string input')
    print(' '*80)
    print('    For example')
    print('*'*80)
    print('"I want to book the show at 12 am on 25th july"')
    print('*'*80)

    return
  X = [word_to_index.get(i,1) for i in s.split()]
  X = pad_sequences(maxlen = 75, sequences = [X], padding = "post", value = word_to_index["PAD"])
  p = model.predict(np.array(X))
  p = np.argmax(p, axis=-1)
  for w, pred in zip(X[0], p[0]):
     if w != 0 and words[w-2]!='Bermel' and idx2tag[pred]!='PAD' and  idx2tag[pred]!='O' and words[w-2]!='UNK':
        # print("{:15}: {}".format(words[w-2], idx2tag[pred]))
        dict[words[w-2]]=idx2tag[pred]

  

  return(dict)

#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

def test():
    print('Testing Rule_based model....')  

    s='i want to fly from mumbai to kolkata on 2nd may with 3000 $'
    if ({'date': '2nd may', 'destination': 'kolkata','location': ['mumbai', 'kolkata'],'money': '3000 $','start': 'mumbai'}==RB_entity(s)):
      print('    RB_PASSED')
    else:
      print('    RB_FAILED')
    print('Testing AI_based model.....')

    s="The Afghan president 's office has responded to criticism by Pakistani President Pervez Musharraf , insisting its intelligence on terrorists hiding in Pakistan is correct"
    if ({'Afghan': 'B-gpe','Musharraf': 'I-per','Pakistan': 'B-geo','Pakistani': 'B-gpe','Pervez': 'I-per','President': 'B-per'}==AI_entity(s)):
      print('    AI_PASSED')
    else:
      print('    AI_FAILED')


    print('Testing AI AND Rule_based model....')

    s='Trump  wants  to fly from delhi to kolkata on 2nd may, saturday in the morning 10 pm'
    if ({'10': 'I-tim',
 '2nd': 'B-org',
 'Trump': 'B-per',
 'date': '2nd may',
 'destination': 'kolkata',
 'location': ['delhi', 'kolkata'],
 'morning': 'B-tim',
 'start': 'delhi',
 'time': '10 pm'}==AI_RB_entity(s)):
      print('    AI_RB_PASSED')
    else:
      print('    AI_RB_FAILED')